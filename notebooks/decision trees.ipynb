{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(300000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 300 seconds\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "%autosave 300\n",
    "pd.options.display.max_columns = None\n",
    "feature_names =defaultdict(lambda:'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification based on published Data:\n",
    "\n",
    "Risk High/low set at 38.40 Readiness high/low set at 46.51\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(row):\n",
    "    if row['overall_risk']== 1 and row['overall_readiness']==1:\n",
    "        return 4\n",
    "    elif row['overall_risk']== 1 and row['overall_readiness']==0:\n",
    "        return 3\n",
    "    elif row['overall_readiness'] == 1:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "risk_ready=pd.read_csv('data/Overall Risk & Readiness Scores.csv')\n",
    "\n",
    "risk_ready_old=risk_ready.columns\n",
    "new_names=['city', 'state', 'geo_id','overall_risk', 'overall_readiness']\n",
    "risk_ready.columns = new_names\n",
    "    \n",
    "#Puerto Rico is being dropped at rows [19, 35, 193, 220] because of data inconsistency\n",
    "risk_ready.drop([19, 35, 193, 220], inplace = True)\n",
    "risk_ready['overall_risk'] = np.where(risk_ready['overall_risk']>=.3840, 1, 0)\n",
    "risk_ready['overall_readiness'] = np.where(risk_ready['overall_readiness']>=.4651, 1, 0)\n",
    "risk_ready['risk_ready_cat']=risk_ready.apply(lambda row: categorize(row), axis=1)\n",
    "\n",
    "\n",
    "risk_ready.to_csv('data/transformed_data/risk_and_readiness_target_data.csv')\n",
    "risk_ready_dict = dict(zip(new_names, risk_ready_old))\n",
    "feature_names['risk_ready']=risk_ready_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean main data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP_water_all</th>\n",
       "      <th>perc_fff</th>\n",
       "      <th>d_plan</th>\n",
       "      <th>w_plan</th>\n",
       "      <th>base_w_stress</th>\n",
       "      <th>invest</th>\n",
       "      <th>tax_break</th>\n",
       "      <th>corruption</th>\n",
       "      <th>perc_vote</th>\n",
       "      <th>innovate</th>\n",
       "      <th>climate_real</th>\n",
       "      <th>hs_ed</th>\n",
       "      <th>pop_dens</th>\n",
       "      <th>w_quality</th>\n",
       "      <th>debt</th>\n",
       "      <th>flood_pop</th>\n",
       "      <th>flood_build</th>\n",
       "      <th>flood_car</th>\n",
       "      <th>impervious</th>\n",
       "      <th>beds_1000</th>\n",
       "      <th>alone_65</th>\n",
       "      <th>child_5</th>\n",
       "      <th>health_ins</th>\n",
       "      <th>older_1999</th>\n",
       "      <th>mobile_home</th>\n",
       "      <th>rent_50plus</th>\n",
       "      <th>trees</th>\n",
       "      <th>heating</th>\n",
       "      <th>disabled</th>\n",
       "      <th>poverty</th>\n",
       "      <th>older_1979</th>\n",
       "      <th>work_outside</th>\n",
       "      <th>no_car</th>\n",
       "      <th>pop_under_1ft</th>\n",
       "      <th>pop_under_3ft</th>\n",
       "      <th>impact_plus1ft</th>\n",
       "      <th>impact_plus3ft</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city_km2</th>\n",
       "      <th>pop_2015</th>\n",
       "      <th>median_income</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>risk_ready_cat</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                GDP_water_all  perc_fff  d_plan  w_plan  base_w_stress  \\\n",
       "risk_ready_cat                                                           \n",
       "1                          48        48      48      48             48   \n",
       "2                          80        80      80      80             80   \n",
       "3                          87        87      87      87             87   \n",
       "4                          59        59      59      59             59   \n",
       "\n",
       "                invest  tax_break  corruption  perc_vote  innovate  \\\n",
       "risk_ready_cat                                                       \n",
       "1                   48         48          48         48        48   \n",
       "2                   80         80          80         80        80   \n",
       "3                   87         87          87         87        87   \n",
       "4                   59         59          59         59        59   \n",
       "\n",
       "                climate_real  hs_ed  pop_dens  w_quality  debt  flood_pop  \\\n",
       "risk_ready_cat                                                              \n",
       "1                         48     48        48         48    48         48   \n",
       "2                         80     80        80         80    80         80   \n",
       "3                         87     87        87         87    87         87   \n",
       "4                         59     59        59         59    59         59   \n",
       "\n",
       "                flood_build  flood_car  impervious  beds_1000  alone_65  \\\n",
       "risk_ready_cat                                                            \n",
       "1                        48         48          48         48        48   \n",
       "2                        80         80          80         80        80   \n",
       "3                        87         87          87         87        87   \n",
       "4                        59         59          59         59        59   \n",
       "\n",
       "                child_5  health_ins  older_1999  mobile_home  rent_50plus  \\\n",
       "risk_ready_cat                                                              \n",
       "1                    48          48          48           48           48   \n",
       "2                    80          80          80           80           80   \n",
       "3                    87          87          87           87           87   \n",
       "4                    59          59          59           59           59   \n",
       "\n",
       "                trees  heating  disabled  poverty  older_1979  work_outside  \\\n",
       "risk_ready_cat                                                                \n",
       "1                  48       48        48       48          48            48   \n",
       "2                  80       80        80       80          80            80   \n",
       "3                  87       87        87       87          87            87   \n",
       "4                  59       59        59       59          59            59   \n",
       "\n",
       "                no_car  pop_under_1ft  pop_under_3ft  impact_plus1ft  \\\n",
       "risk_ready_cat                                                         \n",
       "1                   48             48             48              48   \n",
       "2                   80             80             80              80   \n",
       "3                   87             87             87              87   \n",
       "4                   59             59             59              59   \n",
       "\n",
       "                impact_plus3ft  lat  long  city_km2  pop_2015  median_income  \n",
       "risk_ready_cat                                                                \n",
       "1                           48   48    48        48        48             48  \n",
       "2                           80   80    80        80        80             80  \n",
       "3                           87   87    87        87        87             87  \n",
       "4                           59   59    59        59        59             59  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_ind = pd.read_csv('data/City Indicators.csv')     \n",
    "\n",
    "\n",
    "city_ind_old=city_ind.columns\n",
    "new_names=['city','state','geo_id','GDP_water_all','perc_fff','d_plan','w_plan','base_w_stress','invest','tax_break','corruption','perc_vote','innovate','climate_real','hs_ed','pop_dens','w_quality','debt','flood_pop','flood_build','flood_car','impervious','beds_1000','alone_65','child_5','health_ins','older_1999','mobile_home','rent_50plus','trees','heating','disabled','poverty','older_1979','work_outside','no_car','pop_under_1ft','pop_under_3ft','impact_plus1ft','impact_plus3ft', 'col_empty','lat','long','county','region','city_km2','pop_2010','pop_2011','pop_2012','pop_2013','pop_2014','pop_2015','median_income']\n",
    "city_ind.columns = new_names\n",
    "\n",
    "city_ind.drop(columns =['col_empty'], inplace= True)\n",
    "indicators_dict = dict(zip(city_ind.columns, city_ind_old))\n",
    "\n",
    "\n",
    "\n",
    "#Puerto Rico is being dropped at rows [19, 35, 193, 220] because of data inconsistency\n",
    "city_ind.drop([19, 35, 193, 220], inplace = True)\n",
    "#two cities had their order of magnitude incorrect for % of people in floodzone. Their neighboring values match the lower magnitude'\n",
    "city_ind=city_ind.replace(412.9208681,41.29208681)\n",
    "city_ind=city_ind.replace(101.6959823,10.16959823)\n",
    "city_ind.replace('Bayam<U+0086>n','Bayamon')\n",
    "city_ind['risk_ready_cat']= risk_ready['risk_ready_cat']\n",
    "\n",
    "city_ind['d_plan'] = city_ind['d_plan'].map({'Yes': 1, 'No': 0})\n",
    "city_ind['w_plan'] = city_ind['w_plan'].map({'Yes': 1, 'No': 0})\n",
    "cities=city_ind['city']\n",
    "#cities.to_csv('data/transformed_data/cities.csv')\n",
    "city_ind.drop(columns=['city','state','geo_id','county', 'region','pop_2010', 'pop_2011', 'pop_2012', 'pop_2013', 'pop_2014'], inplace=True)\n",
    "\n",
    "city_ind.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "#city_ind.to_csv('data/transformed_data/city_indicators_cleaned.csv')\n",
    "city_ind.groupby('risk_ready_cat').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.indexes.base.Index"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trees_cat=city_ind['risk_ready_cat']\n",
    "trees_data = city_ind.drop(columns=['risk_ready_cat'])\n",
    "tree_features=trees_data.columns\n",
    "#trees_cat.to_csv('data/transformed_data/classification_labels.csv')\n",
    "#trees_data.to_csv('data/transformed_data/classification_data.csv')\n",
    "#tree_features.to_csv('data/transformed_data/classification_features.csv')\n",
    "\n",
    "\n",
    "type(tree_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    prob=rf.predict_proba(X_test)\n",
    "    fpr,tpr,thresholds = roc_curve(y_test, prob[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "             label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "    i += 1\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sss_rf mean accuracy= 0.7428571428571428\n",
      "[3 2 2 1 3 2 3 4 4 4 1 3 3 1 1 3 1 3 2 3 2 2 4 2 4 4 3 2]\n",
      "[3 2 2 2 3 2 3 2 3 4 3 3 3 1 2 3 2 3 2 3 2 2 4 2 4 2 3 2]\n",
      "TP= [0 2 1 3], fp=[0 8 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "from scipy import interp\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "X=np.array(trees_data)\n",
    "y=np.array(trees_cat)\n",
    "sss = StratifiedShuffleSplit(n_splits=5, random_state=42)\n",
    "sss.get_n_splits(X,y)\n",
    "split_indices=list(sss.split(X,y))\n",
    "#print(split_indices)\n",
    "     \n",
    "sss_rf_scores =[]\n",
    "\n",
    "'''\n",
    "RandomForestClassifier(n_estimators=’warn’, criterion=’gini’, max_depth=None,\n",
    "min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None,\n",
    "min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, \n",
    "n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None)\n",
    "'''\n",
    "n=155\n",
    "c = None\n",
    "m=2\n",
    "f='auto'\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    sss_rf = OneVsRestClassifier(RandomForestClassifier( n_jobs=-1, max_features = f, \n",
    "            max_depth= c, n_estimators=n, min_samples_split=m,random_state=38))\n",
    "    sss_rf.fit(X_train, y_train)\n",
    "    y_hat=sss_rf.predict(X_test)\n",
    "    #print(y_hat,y_test)\n",
    "    score=sss_rf.score(X_test,y_test)\n",
    "    sss_rf_scores.append(score)\n",
    "    #print(score)\n",
    "    \n",
    "sss_rf_mean_accuracy=sum(sss_rf_scores)/len(sss_rf_scores)\n",
    "print(f'sss_rf mean accuracy= {sss_rf_mean_accuracy}')\n",
    "sss_rf_feat=pd.DataFrame()\n",
    "\n",
    "sss_rf_feat['features']=trees_data.columns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(y_test)\n",
    "print(y_hat)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_hat)\n",
    "print(f'TP= {tp}, fp={fp}')\n",
    "#sss_rf mean accuracy= 0.7571428571428571\n",
    "filename = 'data/models/oneVRest_Random_Forest.sav'\n",
    "pickle.dump(sss_rf, open(filename, 'wb'))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trees_cat=city_ind['risk_ready_cat']\n",
    "trees_data = city_ind.drop(columns=['risk_ready_cat'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(trees_data, trees_cat, test_size=0.25, random_state=42)\n",
    "rf_scores=[]\n",
    "\n",
    "n=125\n",
    "c = 8\n",
    "m=10\n",
    "f='auto'\n",
    "\n",
    "rf = OneVsRestClassifier(RandomForestClassifier(max_features = f,\n",
    "    max_depth= c, n_estimators=n, min_samples_split=m,\n",
    "    random_state=38,n_jobs=-1))\n",
    "rf.fit(X_train, y_train)\n",
    "y_hat=rf.predict(X_test)\n",
    "#print(y_hat,y_test)\n",
    "score=rf.score(X_test,y_test)\n",
    "print(score)\n",
    "    \n",
    "\n",
    "rf_feat=pd.DataFrame()\n",
    "\n",
    "rf_feat['features']=trees_data.columns\n",
    "#print (y_hat, y_test)\n",
    "#rf_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trees_cat=city_ind['risk_ready_cat']\n",
    "trees_data = city_ind.drop(columns=['risk_ready_cat'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(trees_data, trees_cat, test_size=0.25, random_state=42)\n",
    "rf_scores=[]\n",
    "\n",
    "n=19\n",
    "c = 10\n",
    "m=13\n",
    "f=8\n",
    "\n",
    "rf = RandomForestClassifier(max_features = f,\n",
    "    max_depth= c, n_estimators=n, \n",
    "                            min_samples_split=m,\n",
    "    random_state=38,n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_hat=rf.predict(X_test)\n",
    "#print(y_hat,y_test)\n",
    "score=rf.score(X_test,y_test)\n",
    "print(score)\n",
    "print()\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_hat)\n",
    "print(f'TP= {tp}, fp={fp}')\n",
    "rf_feat=pd.DataFrame()\n",
    "\n",
    "rf_feat['features']=trees_data.columns\n",
    "#print (y_hat, y_test)\n",
    "#rf_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "'''\n",
    "AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm=’SAMME.R’, \n",
    "random_state=None\n",
    "'''\n",
    "#n_estimators =49, learning_rate = 1.1\n",
    "n=49\n",
    "le=1.1\n",
    "ada_scores =[]\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    ada = OneVsRestClassifier(AdaBoostClassifier(n_estimators =n, learning_rate = le, random_state=38))\n",
    "    ada.fit(X_train, y_train)\n",
    "    y_hat=ada.predict(X_test)\n",
    "    score=ada.score(X_test,y_test)\n",
    "    ada_scores.append(score)\n",
    "    \n",
    "    \n",
    "ada_mean_accuracy=sum(ada_scores)/len(ada_scores)\n",
    "\n",
    "print(f'ada boost mean accuracy= {ada_mean_accuracy}')\n",
    "ada_feat=pd.DataFrame()\n",
    "\n",
    "ada_feat['features']=trees_data.columns\n",
    "#ada_feat['Importance']=rf.feature_importances_\n",
    "\n",
    "#ada boost mean accuracy= 0.7285714285714285"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                        \n",
    "\n",
    "data = np.random.rand(5, 10)  # 5 entities, each contains 10 features\n",
    "label = np.random.randint(2, size=5)  # binary target\n",
    "dtrain = xgb.DMatrix(data, label=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "'''\n",
    "AdaBoostClassifier(base_estimator=None, n_estimators=50, learning_rate=1.0, algorithm=’SAMME.R’, \n",
    "random_state=None\n",
    "'''\n",
    "#n_estimators =49, learning_rate = 1.1\n",
    "n=49\n",
    "le=1.1\n",
    "#ada_scores =[]\n",
    "\n",
    "\n",
    "\n",
    "ada_l = AdaBoostClassifier(n_estimators =n, learning_rate = le, random_state=38)\n",
    "ada_l.fit(X_train, y_train)\n",
    "y_hat=ada_l.predict(X_test)\n",
    "score=ada_l.score(X_test,y_test)\n",
    "#ada_scores_l.append(score)\n",
    "\n",
    "    \n",
    "#ada_mean_accuracy=sum(ada_scores)/len(ada_scores)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_hat)\n",
    "print(f'TP= {tp}, fp={fp}')\n",
    "print(f'ada_last accuracy= {score}')\n",
    "ada_feat=pd.DataFrame()\n",
    "\n",
    "ada_feat['features']=trees_data.columns\n",
    "#ada_feat['Importance']=rf.feature_importances_\n",
    "\n",
    "#ada boost mean accuracy= 0.7285714285714285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dataset = pd.read_csv('data/winequality.csv')\n",
      "dataset.isnull().any() #does a True/False for nulls\n",
      "dataset = dataset.fillna(method='ffill') \n",
      "\n",
      "X = dataset.drop(['quality'], axis=1).values \n",
      "y = dataset['quality'].values\n",
      "\n",
      "# Binarize the output\n",
      "y = label_binarize(y, classes=[1,2,3,4,5])\n",
      "n_classes = y.shape[1]\n",
      "\n",
      "\n",
      "# shuffle and split training and test sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
      "                                                    random_state=0)\n",
      "\n",
      "# Learn to predict each class against the other\n",
      "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
      "                                 random_state=42))\n",
      "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/winequality.csv' does not exist: b'data/winequality.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-c5d95d13a97a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/winequality.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#does a True/False for nulls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ffill'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu-cuda8\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu-cuda8\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu-cuda8\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu-cuda8\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu-cuda8\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/winequality.csv' does not exist: b'data/winequality.csv'"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "dataset = pd.read_csv('data/winequality.csv')\n",
    "dataset.isnull().any() #does a True/False for nulls\n",
    "dataset = dataset.fillna(method='ffill') \n",
    "\n",
    "X = dataset.drop(['quality'], axis=1).values \n",
    "y = dataset['quality'].values\n",
    "\n",
    "# Binarize the output\n",
    "y = label_binarize(y, classes=[1,2,3,4,5])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=42))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#Plot ROC curves for the multiclass problem\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
